import streamlit as st
import feedparser
import pandas as pd
from datetime import datetime
import urllib.parse

st.set_page_config(page_title="24H å…¨çƒè²¡ç¶“å³æ™‚ç›£æ§", layout="wide")

def get_google_news(search_query):
    # å„ªåŒ–æœå°‹èªæ³•ï¼šç§»é™¤éå¤šçš„ ORï¼Œç¢ºä¿æœå°‹çµæœç²¾æº–
    encoded_query = urllib.parse.quote(search_query)
    # å¢åŠ æ™‚å€è¨­å®šèˆ‡æ’åºé‚è¼¯
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    
    feed = feedparser.parse(rss_url)
    return feed.entries[:10]

st.title("ğŸ“Š 24H è²¡ç¶“æ–°èå³æ™‚ç›£æ§")
st.write(f"æœ€å¾Œæ›´æ–°æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ç²¾ç°¡é—œéµå­—ï¼Œå¢åŠ æœå°‹å‘½ä¸­ç‡
categories = {
    "ğŸŒ ç¸½é«”ç¶“æ¿Ÿ": "ç¸½é«”ç¶“æ¿Ÿ OR é€šè†¨ OR è¯æº–æœƒ",
    "ğŸ‡ºğŸ‡¸ ç¾è‚¡é‡å¤§æ–°è": "ç¾è‚¡ OR æ¨™æ™®500 OR Nvidia",
    "ğŸ‡¹ğŸ‡¼ å°è‚¡é‡å¤§æ–°è": "å°è‚¡ OR å°ç©é›»",
    "ğŸ‡¯ğŸ‡µ æ—¥è‚¡é‡å¤§æ–°è": "æ—¥è‚¡ OR æ—¥ç¶“225 OR æ—¥åœ“"
}

tabs = st.tabs(list(categories.keys()))

for i, (name, query) in enumerate(categories.items()):
    with tabs[i]:
        articles = get_google_news(query)
        if not articles:
            # å¦‚æœ 24 å°æ™‚å…§æ²’æ–°èï¼Œå˜—è©¦æ“´å¤§åˆ° 2 å¤© (when:2d)
            st.info(f"ğŸ” æ­£åœ¨å˜—è©¦æ“´å¤§æœå°‹ç¯„åœ...")
            alt_query = urllib.parse.quote(query)
            articles = feedparser.parse(f"https://news.google.com/rss/search?q={alt_query}+when:2d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant").entries[:5]
        
        if articles:
            for entry in articles:
                with st.container():
                    st.markdown(f"### [{entry.title}]({entry.link})")
                    st.caption(f"ğŸ“… {entry.published}  |  ä¾†æºï¼š{getattr(entry, 'source', {'title': 'Google News'}).get('title')}")
                    st.divider()
        else:
            st.warning(f"ç›®å‰æš«ç„¡ {name} çš„ç›¸é—œæ–°èï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
